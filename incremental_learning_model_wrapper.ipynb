{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "incremental_learning_model_wrapper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM0xpThbW3cUxNQ7Bp1UMp9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saran-nns/incremental_learning_tf2.0/blob/master/incremental_learning_model_wrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G20jqN06tTXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX-Cv5Wwts3F",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Z3Vxc9tanf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = datasets.cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DKjQek3tNJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_dataset_loader(dataset = dataset, new_data = None, old_labels=[0,1,2,3,4,5,6,7], new_labels= [8,9]):\n",
        "  \n",
        "  filtered_training_data = []\n",
        "  filtered_labels = []\n",
        "  allowed_labels = old_labels + new_labels\n",
        "  \n",
        "  # Pick only the data with required labels\n",
        "  for i, _ in enumerate(dataset[0][0]):\n",
        "    if dataset[0][1][i] in allowed_labels:\n",
        "      filtered_training_data.append(dataset[0][0][i]/np.float32(255))\n",
        "      filtered_labels.append(dataset[0][1][i])\n",
        "\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((filtered_training_data, filtered_labels))\n",
        "  # TODO: new_dataset = train_dataset+old_dataset\n",
        "  train_dataset.shuffle(len(list(train_dataset)))\n",
        "\n",
        "  # Split into train and test (80%, 20%)\n",
        "  trainind_dataset_size = int(len(list(train_dataset))*0.8)\n",
        "  train_ds,test_ds = train_dataset.take(trainind_dataset_size), train_dataset.skip(trainind_dataset_size)\n",
        "\n",
        "  # Split the images and labels in train and test datasets\n",
        "  train_images,train_labels= np.array(list(train_ds))[:,0],np.array(list(train_ds))[:,1]\n",
        "  train_images,train_labels = tf.convert_to_tensor(train_images.tolist()), tf.convert_to_tensor(train_labels.tolist())\n",
        "  test_images,test_labels = np.array(list(test_ds))[:,0],np.array(list(test_ds))[:,1]\n",
        "  test_images,test_labels = tf.convert_to_tensor(test_images.tolist()),tf.convert_to_tensor(test_labels.tolist())\n",
        "  print('Shape of training images after filtering labels',np.shape(train_images))\n",
        "\n",
        "  return train_images,train_labels,test_images,test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlJXDwWJtvVk",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8SbDsMWAq0P",
        "colab_type": "text"
      },
      "source": [
        "##### Conditions for adding new layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGNDyg7ltg13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeatureExtractor(Model):\n",
        "  def __init__(self,trainable):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu',trainable = trainable)\n",
        "    self.maxpool = MaxPooling2D((2,2))\n",
        "    self.conv2 = Conv2D(64, 3, activation='relu',trainable = trainable)\n",
        "    self.conv3 = Conv2D(64,3,activation='relu',trainable = trainable)\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.conv3(x)\n",
        "    return x\n",
        "\n",
        "class Classifier(Model):\n",
        "  def __init__(self, n_classes):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.flatten = Flatten()\n",
        "    self.n_classes = n_classes\n",
        "    self.d1 = Dense(64, activation='relu')\n",
        "    self.d2 = Dense(n_classes)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "class IncrementalLearning(Model):\n",
        "  def __init__(self, feature_extractor,classifier, is_online = False):\n",
        "    super(IncrementalLearning, self).__init__()\n",
        "    self.feature_extractor=feature_extractor\n",
        "    if is_online:\n",
        "      self.feature_extractor.trainable = False\n",
        "      # Clone the old classifier weights and  set it non-trainable\n",
        "      classifier.trainable = False\n",
        "      # Add new prediction layer and set it trainable\n",
        "      self.new_prediction_layer = tf.keras.layers.Dense(classifier.n_classes,trainable=True)\n",
        "      self.classifier= tf.keras.Sequential([classifier, self.new_prediction_layer])\n",
        "    else:\n",
        "      self.classifier = classifier\n",
        "\n",
        "  def call(self, x):\n",
        "    features = self.feature_extractor(x)\n",
        "    x = self.classifier(features)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chhYAHUb1QU0",
        "colab_type": "code",
        "outputId": "09d56733-4060-4053-c887-893f282a7dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "x = Classifier(10)\n",
        "x.build((64,))\n",
        "var= [var.name for var in x.trainable_variables]\n",
        "var"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dense_12/kernel:0',\n",
              " 'dense_12/bias:0',\n",
              " 'dense_13/kernel:0',\n",
              " 'dense_13/bias:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhAFuSUEuv-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extractor = FeatureExtractor(trainable=True)\n",
        "classifier = Classifier(10)\n",
        "model = IncrementalLearning(feature_extractor,classifier,is_online=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d_4WO01tLcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.build((None,32,32,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QIkFmChwBvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "518f8034-66d6-4a30-b070-a20d70cf76ef"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"incremental_learning_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "feature_extractor_5 (Feature multiple                  56320     \n",
            "_________________________________________________________________\n",
            "classifier_7 (Classifier)    multiple                  66250     \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVAiQcT7okO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extractor1 = FeatureExtractor(trainable=False)\n",
        "classifier1 = Classifier(10)\n",
        "model2 = IncrementalLearning(feature_extractor,classifier,is_online=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GviDAEPaCrbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "c2668e61-9a29-4eac-b2e5-a4cf1ae098f9"
      },
      "source": [
        "model2.build((None,32,32,3))\n",
        "model2.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"incremental_learning_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "feature_extractor_5 (Feature multiple                  56320     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             multiple                  110       \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      multiple                  66360     \n",
            "=================================================================\n",
            "Total params: 122,680\n",
            "Trainable params: 110\n",
            "Non-trainable params: 122,570\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McYUzzAsFenB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}